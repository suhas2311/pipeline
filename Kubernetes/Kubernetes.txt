Kubernetes Installation 
	Minimum requirement for K8S master node is (2-core CPU and 2GB Ram)
	
	1. sudo apt update 
	2. sudo apt-get install -y apt-transport-https
	3. sudo su -
	4. curl -s https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add
	5. echo 'deb http://apt.kubernetes.io/ kubernetes-xenial main' > /etc/apt/sources.list.d/kubernetes.list
	6. exit from sudo 
	7. sudo apt update 
	8. sudo apt install -y docker.io
	
	9. sudo systemctl start docker 
	10. sudo systemctl enable docker.service 
	
	11. sudo apt-get install -y kubelet kubeadm kubectl kubernetes-cni
	
	12. Login back to master node,  make sure below steps are executed before running kubeadm init 
		1. sudo su - 
		2. docker cgroup driver configuration need to be updated 
			1. add the below content to the file /etc/docker/daemon.json
				{
				  "exec-opts": ["native.cgroupdriver=systemd"]
				}
			2. systemctl daemon-reload
			   systemctl restart docker 

			   systemctl restart kubectl (optional for first time)	
	
	Take ami from the above ec2 instances to create worker nodes 
		
	13. kubeadm init 
			if this command executes successfully then we get kubeadm join command with token
			save this command in seperate file for worker nodes to add to this master.

	14. k8s configurations for kubectl command 
		1. exit from root 
		2. copy the default k8s conf file to home 
			a. mkdir -p $HOME/.kube
			b. sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
			c. sudo chown $(id -u):$(id -g) $HOME/.kube/config

	15. For now open all ports in master 
		
	16. Now Install k8s CNI driver
			1. sudo sysctl net.bridge.bridge-nf-call-iptables=1
			2. kubectl apply -f "https://cloud.weave.works/k8s/v1.13/net.yaml"
						
	17. Login to worker nodes 
		a. sudo su -
		
		b. systemctl daemon-reload 
		   systemctl restart docker 
	           systemctl restart kubectl 	
			
		c. Run the kubeadm join <TOKEN> command which we get from kubeadm init from master 
		
	18. In master node check for the worker nodes.
		kubectl get nodes 
			
			
kubernetes Architecture 	
	The architecture of k8s differs from master and worker node 

	Master node components 
		1. Api Server / kube-api-server
			- It is the main management point of the cluster and also called 
			  as brain of the cluster.
			- All the components are directly connected to API serve, they 
			  communicate through API server only and no other component will 
			  communicate directly with each other.
			- This is the only component which connects and got access to etcd.
			- All the cluster requests are authenticated and authorised by API server.
			- API server has a watch mechanism for watching the changes in cluster.
			
		2. etcd 
			- ectd is a distributed , consistent key value store used for 
			  storing the complete cluster information/data.
			- ectd contains data such as configuration management of cluster,
              distributed work and basically complete cluster information.			
			
		3. scheduler / kube-scheduler
			- The scheduler always watches for a new pod request and 
			  decides which worker node this pod should be created.
			- Based on the worker node load, affinity and anti-affiny, taint configuration 
			  pod will be scheduled to a particular node.
			  
		Controller manager /control manager / kube-controller 
			- It is a daemon that always runs and embeds core control loops known as controllers. 
			- K8s has some inbuild controllers such as Deployment, DaemonSet, ReplicaSet, Replication controller,
			  node controller, jobs, cronjob, endpoint controller, namespace controller etc.	
			
		Cloud controller manager 
			- These controller help us to connect with the public cloud provider service and this component 
			  is maintained by cloud providers only.

Worker node components 
		kubelet 
			- It is an agent that runs on each and every worker node and it alsways watches the API 
			  server for pod related changes running in its worker node.
			- kubelet always make sure that the assigend pods to its worker node is running.
			- kubelet is the one which communicates with containarisation tool (docker daemon)
              		  through docker API (CRI). 	
			- work of kubelet is to create and run the pods. Always reports the status of the worker node 
			  and each pod to API server. (uses a tool call cAdvisor)
			- Kubelet is the one which runs probes.	
		
		kube service proxy 
			(in k8s service means networking)
			- Service proxy runs on each and every worker node and is responsble for watching API 
			  server for any changes in service configuration (any network related configuration).	
			- Based on the configuration service proxy manages the entire network of worker node.

		Container runtime interface (CRI)
			- This component initialy identifies the container technology and connects it to kubelet.
			
			
		pod
			- pods are the smallest deployable object in kuberntes.
			- pod should contain atleast one container and can have n number of containers.
			- If pod contains more than one container all the container share the same memory assigned to that pod.

YAML file 
	- filetype .yaml or .yml 
	- YAML file contains key - value pairs where key are fixed and defined by the 
	  kubernetes and value is user defined configuration.
	- Values supoorts multiple datatypes - string, Integer, Boolean, Array, List.	
	
	example: List representation  
	
			1) name: Harsha
			   hobbies: ["Driving","coding"]
					
						(or)
				
			   name: Harsha
			   hobbies: 
				   - Driving
				   - coding

k8s yaml syntax example with pod:
	
	apiVersion: v1
	kind: Pod 
	metadata: 
    	    name: my-first-pod	
	spec: 
    	    containers:
       		- name: my-nginx 
         	  image: nginx:latest
		  ports: 
		    - containerPort: 80 	
	
	apiVersion: v1
		- This is the version of api used to create a k8s object.
		- The fields are case-sensitive and YAML use camelcase.
		- The type of api are alpha, beta and stable.
		
	kind: Pod
		- here we specify which object we need to create. 
		- Always object name first letter is capital.
		
	metadata:
	    - This field is used to provide information on the object 
		  which we are creating.
		- Information such as name, labels and annotations. 	
	
	spec:
		- This is used to do the actual configuration of the 
		  object.

		 ports: 
		    - containerPort: 80
	

To create / apply a configuration 
	kubectl apply -f <file>.yml	
	
To list objects 
	kubectl get <obeject_type>
		ex: List pods - kubectl get pods 
		    List deployment - kubectl get deployments
			
To delete objects 
	kubectl delete <object_type>


Assignment: What happens if we create a pod with kubectl ?		  

K8S Labels and selectors 
	- K8S labels is a metadata key value which can be applied to any object in k8s.
	- Labels are used to identify by using selectors.
	- Multiple objects can have same label, multiple labels to same object and Label length should be less that 63 characters.
	
	TO list all labels of a object 
		kubectl get <obeject_type> <obejct_name> --show-labels 
	
	
	Selectors 
		- Selectors are used to filter and identifly the labeled k8s object.
		
		Equality-Based 
			- It will use only one label in comparision and it will look for objects with exact same 
			  string in label.
			- we can use 3 types of operators equal ( = or == ) and not-qual ( != )	
		
			example: 
				selectors: 
					matchLabels: 
						app=nginx 
						   (or)
						app: nginx   
		
		set-based 
			- This type of selector allows us to filter objects based on multiple set of values to a label key.
			- 3 types of operators we can use in, notin and exists.

				example: 
					selectors: 
						matchLabels: 
							app in (nginx, my-nginx)
							app exits (nginx, my-nginx)
							app notin (nginx, my-nginx)
Annotations 
	- These are used for record purpose only and to provide some user information to objects.
	- These are non-identifying metadata so we cannot use selectors on annotations.

	example: personal_info, phone_number, imageregistry, author	
	
Assignment: Difference b/w set-based and equality-based selector.
			Difference b/w labels and annotations.

ReplicaSet vs Replication Controller
	- Both ensures that a specified number of pod replicas are alyways running at a given point of time.
	- Replication controller is a very old way of replicating the pos and now it is replaced by ReplicaSet
      
	- The only differenece b/w them is their selector types.
		Replication Controller supports only equality-based selector. 
		ReplicaSet supports both equality-based and set-based selectors.

Deployment controller / Deployment / k8s deployment 
	- Deployment is used to create replicas of pod and it makes sure at a given point of time 
	  the number of replicas of pod is alway running. 
	- Deployment internally uses ReplicaSet to replicate the pods.
	- If we update the configuration in deployment it will automatically updates it to all the pods.
	- Rollout and Rollback of pod update is possible.
	- we can pause a deployment whenerver we need.
	- Deployment has got its own internal autoscaller which is of type horizontal scaller. 
		To apply calling 
			kubectl autoscale deployment.v1.apps/<deployment_name> --min=5 --max=20 --cpu-percent=50	
	- scaleup and scaledown is possible by increasing and decreasing the replica count at any given 
	  point of time.
		kubectl scale deployment.v1.apps/<deployment_name> --replicas=10	
	
	- deployment is a cluster level object.
	
		deployment = pod + ReplicaSet + autoscaling + RollingUpdates 
	
	Deployment spec file.
		
		apiVersion: apps/v1
		kind: Deployment
		metadata:
		  name: nginx-deployment-new
		  labels:
			app: my-deployment-nginx
		spec:
		  replicas: 5
		  selector:
			matchLabels:
			  app=nginx
		  template:
			metadata:
			  labels:
				app: nginx
			spec:
			  containers:
			  - name: nginx
				image: nginx:1.14.2
				ports:
				- containerPort: 80
	
Assignment: demo on selectors types 
		  
	
DaemonSet
	- DaemonSet ensures that a copy of pod is always running on all the worker nodes in the cluster.
	-If a new node is added or if deleted DaemonSet will automatically adds/deletes the pod.

	usage: 
		- we use DaemonSet to deploy monitoring agents in every worker node.
		- Log collection daemons: to grab the logs from worker and all the pods running in it.
		
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: nginx-daemonset
spec:
  selector:
	matchLabels:
	  app: daemonset-nginx
  template:
	metadata:
	  labels:
		app: daemonset-nginx
	spec:
	  containers:
	  - name: nginx
		image: nginx:1.14.2
		ports:
		 - containerPort: 80
		 
Statefull Applications 
	- User session data is saved at the server side.
	- if server goes down, it is difficult to transfer the session data to other server. 
	- This type of application will not work, if we want to implement autoscaling.
	
Stateless Applications
	- user session-data is never saved at the server side.
	- using a common authentication gateway / client token method to validate the users 
	  once for multiple microservices.	
		
https://medium.com/tech-tajawal/microservice-authentication-and-authorization-solutions-e0e5e74b248a		

Monolothic and Microservice architecture 

	Monolothic architecture
		- A monolothic application has a single code base with multiple modules in it.
		- It is a single build for entire application.
		- To make minor changes to application, we need to re-build and re-deploy the 
		  complete application.
		- scaling is very challenging.
			
	Microservice architecture 
		- A microservice application is composed of small (micro) services. 
		- Each service will have a different code base.
		- Application are divided into as small as possible sub applications called services
		  which are independent to each other which are called loosely coupled.	
		- Each service can be managed separately and it is deployable separately.
		- Services need not to share same technology stack or frameworks.		 

StatefulSet 
	- StatefulSet = Deployment + sticky identity for each and every pod replica.
	- Unlike a deployment a StatefulSet maintains a sticky identity for each of the pod.
		
Node controller 
	- Looks for node statuses and responds to API server only when a node is down.

Endpoint Controller
	- Populates the information of endpoints of all the objects.	

		
Service (svc)
	- Service is an REST api objects with set of policies for defining the 
	  access to set of pods.
	- Services are the default load balancer in k8s.
	- services are always created and works at cluster level.
	- services are the networking configurations which we do in k8s.
	- k8s prefers to use 30000 - 50000 range of ports to define services.

1. ClusterIP
	- This is the default type of service which exposes the IPs of pod to the other pods 
	  with in the same cluster.
	- ClusterIP cannot be accessed outside cluster.
	- services are the default loadbalancers of k8s.
	
	apiVersion: v1 
	kind: Service 
	metadata:
	     name: my-svc 
	spec: 
		type: ClusterIP
		selector: 
			app: my-nginx 
		ports: 
			- name: http
			  port: 30080
			  targetPort: 8080	

2. nodePort 
	- A nodeport service is the most primitive way to get the external traffic directed to our services / applications 
	  running inside a pod within the cluster.
	- By default NodePort acts as a load balancer. 
	- Automatically a ClusterIP will be created internally. 
	
		NodePort = ClusterIP + a port mapping to the all the nodes of cluster.
		
	- If we wont specify any port while creating nodeport, k8s will automatically asign a port between the range 30000 - 32767
	- By default nodeport will open the port in all the node in cluster including master node.	
	
	apiVersion: v1 
	kind: Service 
	metadata:
	     name: my-svc 
	spec: 
		type: NodePort
		selector: 
			app: my-nginx 
		ports: 
			- name: http
			  nodePort:30082	
			  port: 8080
			  targetPort: 80

		
3. Load Balancer
	- It is a type of service which is used to link external load balancer to the cluster.
	- This type of service is used by cloud providers and this service is completely depends on cloud providers. 
	- K8s now provides a better alternative for this service type which is called Ingress.


4. Headless service 
	headless service 
		  - When we neither need nor want loadbalancig and when we don't want a single IP to a service, we need to use headless service.
		  - Headless service returns all the ips of the pods it is selecting.
		  - headless service is created by specifying none for clusterIP 
		  - headless service is usually used with statefulsets.
		  
	headless with in cluster 

		apiVersion: v1 
		kind: Service 
		metadata:
			 name: my-svc 
		spec: 
			clusterIP: None
			selector: 
				app: my-nginx 
			ports: 
				- name: http
				  port: 30080
				  targetPort: 8080
				  
	headless with nodeport 			  
		nodePort = headless + port mapping 
		
		apiVersion: v1 
		kind: Service 
		metadata:
			 name: my-svc 
		spec: 
			clusterIP: None
			type: NodePort
			selector: 
				app: my-nginx 
			ports: 
				- name: http
				  nodePort:30082	
				  port: 8080
				  targetPort: 80
				  
	1. Create a headless service with statefulsets
	2. Login to any one of pod 
	3. apt install dnsutils and do nslookup <service_name>


Assignment: 
	
A. How to use custom images / connect to a registry through k8s 
	1. Login to the docker hub account 
		  docker login 
	2. Create a app to print ip 
			using flask 
	3. 	push the image to your registry 
	4 use the above custom image in k8s spec file.
	
		image: <username>/<regirty_name>:<tag>
		imagePullPolicy: IfNotPresent
		
	5. Create a service of type NodePort attaching the above pods 

B. How to access application running on one pod from another pod 

C. Demo in service to service communication

D. Headless service example (Need to show the list of all pod ips) 
